import copy
import numpy as np
import torch
import torch.nn as nn
from torch.nn.init import kaiming_normal_
from ..model_utils import model_nms_utils
from ..model_utils import centernet_utils
from ...utils import loss_utils
from ...ops.roiaware_pool3d import roiaware_pool3d_utils
import copy
from copy import deepcopy
import cv2

def get_box3d_point(box_size, heading_angle, center):
    def rotz(t):
        c = np.cos(t)
        s = np.sin(t)
        return np.array([[c, -s,  0],
                        [s,  c,  0],
                        [0,  0,  1]])

    R = rotz(heading_angle)
    l,w,h = box_size
    x_corners = [l/2,l/2,-l/2,-l/2,l/2,l/2,-l/2,-l/2]
    z_corners = [h/2,h/2,h/2,h/2,-h/2,-h/2,-h/2,-h/2]
    y_corners = [w/2,-w/2,-w/2,w/2,w/2,-w/2,-w/2,w/2]
    # rotate and translate 3d bounding box
    corners_3d = np.dot(R, np.vstack([x_corners,y_corners,z_corners]))
    corners_3d[0,:] = corners_3d[0,:] + center[0]
    corners_3d[1,:] = corners_3d[1,:] + center[1]
    corners_3d[2,:] = corners_3d[2,:] + center[2]
    corners_3d = np.transpose(corners_3d)

    return corners_3d

def get_img_points_coor(polygon,point_cloud_range,voxel_size,grid_size):
    polygon[:,0]=np.floor((polygon[:,0]-point_cloud_range[0])/voxel_size[0])
    polygon[:,1]=np.floor((polygon[:,1]-point_cloud_range[1])/voxel_size[0])
    polygon[:,0]  = np.clip(polygon[:, 0], 0, grid_size[0]).astype(np.uint16)
    polygon[:, 1] = np.clip(polygon[:, 1], 0, grid_size[1]).astype(np.uint16)
    return polygon


class SeparateHead(nn.Module):
    def __init__(self, input_channels, sep_head_dict, init_bias=-2.19, use_bias=False):
        super().__init__()
        self.sep_head_dict = sep_head_dict

        for cur_name in self.sep_head_dict:
            output_channels = self.sep_head_dict[cur_name]['out_channels']
            num_conv = self.sep_head_dict[cur_name]['num_conv']

            fc_list = []
            for k in range(num_conv - 1):
                fc_list.append(nn.Sequential(
                    nn.Conv2d(input_channels, input_channels, kernel_size=3, stride=1, padding=1, bias=use_bias),
                    nn.BatchNorm2d(input_channels),
                    nn.ReLU()
                ))
            fc_list.append(nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=1, padding=1, bias=True))
            fc = nn.Sequential(*fc_list)
            if 'hm' in cur_name:
                fc[-1].bias.data.fill_(init_bias)
            else:
                for m in fc.modules():
                    if isinstance(m, nn.Conv2d):
                        kaiming_normal_(m.weight.data)
                        if hasattr(m, "bias") and m.bias is not None:
                            nn.init.constant_(m.bias, 0)

            self.__setattr__(cur_name, fc)

    def forward(self, x):
        ret_dict = {}
        for cur_name in self.sep_head_dict:
            ret_dict[cur_name] = self.__getattr__(cur_name)(x)

        return ret_dict

class SegmentHead(nn.Module):
    def __init__(self, model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, voxel_size):
        super().__init__()
        self.model_cfg = model_cfg
        self.num_class = num_class
        self.grid_size = grid_size
        self.point_cloud_range = point_cloud_range
        self.voxel_size = voxel_size
        self.feature_map_stride = self.model_cfg.get('FEATURE_MAP_STRIDE', None)

        self.class_names = class_names
        self.class_names_each_head = []
        self.class_id_mapping_each_head = []

        for cur_class_names in self.model_cfg.CLASS_NAMES_EACH_HEAD:
            self.class_names_each_head.append([x for x in cur_class_names if x in class_names])
            cur_class_id_mapping = torch.from_numpy(np.array(
                [self.class_names.index(x) for x in cur_class_names if x in class_names]
            )).cuda()
            self.class_id_mapping_each_head.append(cur_class_id_mapping)

        total_classes = sum([len(x) for x in self.class_names_each_head])
        assert total_classes == len(self.class_names), f'class_names_each_head={self.class_names_each_head}'

        self.shared_conv = nn.Sequential(
            nn.Conv2d(
                input_channels, self.model_cfg.SHARED_CONV_CHANNEL, 3, stride=1, padding=1,
                bias=self.model_cfg.get('USE_BIAS_BEFORE_NORM', False)
            ),
            nn.BatchNorm2d(self.model_cfg.SHARED_CONV_CHANNEL,eps=1e-3, momentum=0.01),
            nn.ReLU(),
        )

        self.deblocks = nn.Sequential(
            nn.ConvTranspose2d(self.model_cfg.SHARED_CONV_CHANNEL, self.model_cfg.SHARED_CONV_CHANNEL, 2, stride=2, bias=False),
            nn.BatchNorm2d(self.model_cfg.SHARED_CONV_CHANNEL,eps=1e-3, momentum=0.01),
            nn.ReLU(),
        )

        self.heads_list = nn.ModuleList()
        for idx, cur_class_names in enumerate(self.class_names_each_head):
            cur_head_dict = {}
            cur_head_dict['hm'] = dict(out_channels=len(cur_class_names), num_conv=self.model_cfg.NUM_HM_CONV)
            self.heads_list.append(
                SeparateHead(
                    input_channels=self.model_cfg.SHARED_CONV_CHANNEL,
                    sep_head_dict=cur_head_dict,
                    init_bias=-2.19,
                    use_bias=self.model_cfg.get('USE_BIAS_BEFORE_NORM', False)
                )
            )
        self.forward_ret_dict = {}
        self.build_losses()

    def build_losses(self):
        if self.model_cfg.get("FLOSSSEG",False):
            self.add_module('hm_loss_func', loss_utils.FocalLossSeg())
        else:
            self.add_module('hm_loss_func', loss_utils.CrossEntropyLoss())

    def assign_target_of_single_head(self, points,indices,num_classes, gt_boxes, feature_map_size, feature_map_stride):
        """
        Args:
            gt_boxes: (N, 8)
            feature_map_size: (2), [x, y]

        Returns:

        """
        #import pdb;pdb.set_trace()
        heatmap = gt_boxes.new_zeros(num_classes, feature_map_size[1], feature_map_size[0])
        mask = gt_boxes.new_zeros(num_classes, feature_map_size[1], feature_map_size[0])
        inds = gt_boxes.new_zeros(feature_map_size[1]*feature_map_size[0]).long()

        for k in range(min(500, gt_boxes.shape[0])):
            x, y, z = points[indices[0] == k][:, 1], points[indices[0] ==k][:, 2], points[indices[0] == k][:, 3]
            coord_x = (x - self.point_cloud_range[0]) / self.voxel_size[0] / feature_map_stride
            coord_y = (y - self.point_cloud_range[1]) / self.voxel_size[1] / feature_map_stride
            coord_x = torch.clamp(coord_x, min=0,
                                  max=feature_map_size[0] - 0.5)  # bugfixed: 1e-6 does not work for center.int()
            coord_y = torch.clamp(coord_y, min=0, max=feature_map_size[1] - 0.5)  #
            #center = torch.cat((coord_x[:, None], coord_y[:, None]), dim=-1)
            #center_int = center.int()
            #center_int_float = center_int.float()
            coord_x = coord_x.int()
            coord_y = coord_y.int()
            # if not (0 <= center_int[0] <= feature_map_size[0] and 0 <= center_int[1] <= feature_map_size[1]):
            #     continue
            #coord_x = coord_x[0<=coord_x<=feature_map_size[0]]
            #coord_y = coord_y[0 <= coord_y <= feature_map_size[1]]

            cur_class_id = (gt_boxes[k, -1] - 1).long()
            heatmap[cur_class_id][coord_y.long(),coord_x.long()] = 1

            inds[(coord_y * feature_map_size[0] + coord_x).long()] = 1
            # import pdb;
            #pdb.set_trace()
            center_point = gt_boxes[k,:3].numpy()
            size = gt_boxes[k,3:6].numpy()
            rot = gt_boxes[k,6].numpy()
            corners_3d = get_box3d_point(size, rot, center_point)
            polygon = corners_3d[:4, :2]
            polygon = get_img_points_coor(polygon, self.point_cloud_range, self.voxel_size, self.grid_size)
            polygon = np.expand_dims(polygon, 0).astype(np.int)
            cv2.fillPoly(mask[cur_class_id].numpy(), polygon, 1)

        return heatmap, inds,mask

    def assign_targets(self, gt_boxes, points,feature_map_size=None,feature_map_stride=None, **kwargs):
        """
        Args:
            gt_boxes: (B, M, 8)
            range_image_polar: (B, 3, H, W)
            feature_map_size: (2) [H, W]
            spatial_cartesian: (B, 4, H, W)
        Returns:

        """
        # import pdb;
        #pdb.set_trace()
        feature_map_size = feature_map_size[::-1]  # [H, W] ==> [x, y]
        # feature_map_size = self.grid_size[:2] // target_assigner_cfg.FEATURE_MAP_STRIDE

        batch_size = gt_boxes.shape[0]
        ret_dict = {
            'heatmaps': [],
            'inds': [],
            'masks': [],
            'heatmap_masks': []
        }

        all_names = np.array(['bg', *self.class_names])
        for idx, cur_class_names in enumerate(self.class_names_each_head):
            heatmap_list, inds_list,mask_list = [], [],[]
            for bs_idx in range(batch_size):
                cur_gt_boxes = gt_boxes[bs_idx]
                gt_class_names = all_names[cur_gt_boxes[:, -1].cpu().long().numpy()]
                #print(gt_class_names)
                #import pdb;pdb.set_trace()
                gt_boxes_single_head = []

                for idx, name in enumerate(gt_class_names):
                    if name not in cur_class_names:
                        continue
                    temp_box = deepcopy(cur_gt_boxes[idx])
                    temp_box[-1] = cur_class_names.index(name) + 1
                    gt_boxes_single_head.append(temp_box[None, :])

                if len(gt_boxes_single_head) == 0:
                    gt_boxes_single_head = cur_gt_boxes[:0, :]
                else:
                    gt_boxes_single_head = torch.cat(gt_boxes_single_head, dim=0)

                point_indices = roiaware_pool3d_utils.points_in_boxes_gpu(
                    points[points[:, 0] == bs_idx, 1:4].reshape(1, -1, 3), gt_boxes_single_head[:, :7].reshape(1, -1, 7))
                heatmap, inds,mask = self.assign_target_of_single_head(points[points[:, 0] == bs_idx, :],point_indices,
                    num_classes=len(cur_class_names), gt_boxes=gt_boxes_single_head.cpu(),
                    feature_map_size=feature_map_size,feature_map_stride=feature_map_stride
                )
                #print("####",point_indices.unique(),"####",heatmap.max())
                heatmap_list.append(heatmap.to(gt_boxes_single_head.device))
                inds_list.append(inds.to(gt_boxes_single_head.device))
                mask_list.append(mask.to(gt_boxes_single_head.device))


            ret_dict['heatmaps'].append(torch.stack(heatmap_list, dim=0))
            ret_dict['masks'].append(torch.stack(mask_list, dim=0))
            ret_dict['inds'].append(torch.stack(inds_list, dim=0))
        return ret_dict

    def sigmoid(self, x):
        y = torch.clamp(x.sigmoid(), min=1e-4, max=1 - 1e-4)
        return y

    def get_loss(self):
        pred_dicts = self.forward_ret_dict['pred_dicts']
        target_dicts = self.forward_ret_dict['target_dicts']
        import pdb;
        #pdb.set_trace()
        tb_dict = {}
        loss = 0

        for idx, pred_dict in enumerate(pred_dicts):
            # pred_dict['hm'] = self.sigmoid(pred_dict['hm'])
            batch_size = pred_dict['hm'].shape[0]
            #import pdb;pdb.set_trace()
            if not self.model_cfg.get("MASK_SEG",False):
                hm_loss = self.hm_loss_func(pred_dict['hm'], target_dicts['heatmaps'][idx])
            else:
                if self.model_cfg.get("MASK_SEG_MOTOR",False) and idx !=2:
                    target_dicts['masks'][idx] = None
                hm_loss = self.hm_loss_func(pred_dict['hm'], target_dicts['heatmaps'][idx],mask=target_dicts['masks'][idx])
            #import pdb;pdb.set_trace()
            hm_loss = hm_loss / batch_size
            hm_loss *= self.model_cfg.LOSS_WEIGHTS

            loss += hm_loss
            tb_dict['hm_loss_head_%d' % idx] = hm_loss.item()

        tb_dict['seg_loss'] = loss.item()
        return loss, tb_dict

    def forward(self, data_dict):
        spatial_features_2d = data_dict['spatial_features_2d']
        x = self.shared_conv(spatial_features_2d)
        x = self.deblocks(x)

        pred_dicts = []

        for head in self.heads_list:
            pred_dicts.append(head(x))

        #import pdb;pdb.set_trace()
        #print("####",data_dict['points'].shape)
        if self.training:
            target_dict = self.assign_targets(
                data_dict['gt_boxes'], data_dict['points'],feature_map_size=x.size()[2:],
                feature_map_stride=self.feature_map_stride
            )
            self.forward_ret_dict['target_dicts'] = target_dict
        self.forward_ret_dict['pred_dicts'] = pred_dicts

        return data_dict
